% Attack Method
@inproceedings{goodfellow2015exp,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
URL	= {http://arxiv.org/abs/1412.6572},
booktitle	= {International Conference on Learning Representations}
}

% Linear Related
@inproceedings{biggio2011support,
  title={Support vector machines under adversarial label noise},
  author={Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
  booktitle={Asian conference on machine learning},
  pages={97--112},
  year={2011}
}

@inproceedings{bat2012svm,
    author = {Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
    title = {Poisoning Attacks against Support Vector Machines},
    year = {2012},
    booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
    pages = {1467â€“1474},
    series = {ICML'12}
}

@inproceedings{liu2017robust,
  title={Robust linear regression against training data poisoning},
  author={Liu, Chang and Li, Bo and Vorobeychik, Yevgeniy and Oprea, Alina},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  pages={91--102},
  year={2017}
}

@inproceedings{demontis2016security,
  title={On security and sparsity of linear classifiers for adversarial settings},
  author={Demontis, Ambra and Russu, Paolo and Biggio, Battista and Fumera, Giorgio and Roli, Fabio},
  booktitle={Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)},
  pages={322--332},
  year={2016},
  organization={Springer}
}

@article{megyeri2019adversarial,
  title={Adversarial robustness of linear models: Regularization and dimensionality},
  author={Megyeri, Istv{\'a}n and Heged{\H{u}}s, Istv{\'a}n and Jelasity, M{\'a}rk},
  year={2019},
  booktitle={European Symposium on Artificial Neural Networks}
}

@article{shi2019understanding,
  title={Understanding and Quantifying Adversarial Examples Existence in Linear Classification},
  author={Shi, Xupeng and Ding, A Adam},
  journal={arXiv preprint arXiv:1910.12163},
  year={2019}
}

@inproceedings{li2020adversarial,
  title={On the Adversarial Robustness of Linear Regression},
  author={Li, Fuwei and Lai, Lifeng and Cui, Shuguang},
  booktitle={2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}


@article{javanmard2020precise,
  title={Precise tradeoffs in adversarial training for linear regression},
  author={Javanmard, Adel and Soltanolkotabi, Mahdi and Hassani, Hamed},
  journal={arXiv preprint arXiv:2002.10477},
  year={2020}
}

% Activation Related
@article{xu2019interpreting,
  title={Interpreting adversarial examples by activation promotion and suppression},
  author={Xu, Kaidi and Liu, Sijia and Zhang, Gaoyuan and Sun, Mengshu and Zhao, Pu and Fan, Quanfu and Gan, Chuang and Lin, Xue},
  journal={arXiv preprint arXiv:1904.02057},
  year={2019}
}

@misc{xie2021smooth,
      title={Smooth Adversarial Training},
      author={cihang xie and Mingxing Tan and Boqing Gong and Alan Yuille and Quoc V Le},
      year={2021},
      url={https://openreview.net/forum?id=HN77M0Sdnp2}
}


% Kernel Related
@inproceedings{hao2019defending,
  title={Defending against adversarial examples using defense kernel network.},
  author={Hao, Yuying and Li, Tuanhui and Jiang, Yong and Cheng, Xuanye and Li, Li},
  booktitle={BMVC},
  pages={77},
  year={2019}
}

@inproceedings{taghanaki2019kernelized,
  title={A kernelized manifold mapping to diminish the effect of adversarial perturbations},
  author={Taghanaki, Saeid Asgari and Abhishek, Kumar and Azizi, Shekoofeh and Hamarneh, Ghassan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={11340--11349},
  year={2019}
}


% Sparsity Related
@article{xu2013sparse,
  title={Sparse kernel logistic regression based on L 1/2 regularization},
  author={Xu, Chen and Peng, ZhiMing and Jing, WenFeng},
  journal={Science China Information Sciences},
  volume={56},
  number={4},
  pages={1--16},
  year={2013},
  publisher={Springer}
}

@misc{gop2018combating,
  title={Combating Adversarial Attacks Using Sparse Representations},
  author={Soorya Gopalakrishnan and Zhinus Marzi and Upamanyu Madhow and Ramtin Pedarsani},
  year={2018},
  url={https://openreview.net/forum?id=S10qYwywf},
  booktitle	= {International Conference on Learning Representations: Workshop Track}
}

@article{guo2018sparse,
  title={Sparse dnns with improved adversarial robustness},
  author={Guo, Yiwen and Zhang, Chao and Zhang, Changshui and Chen, Yurong},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={242--251},
  year={2018}
}


@article{li2020adversarial,
  title={On the Adversarial Robustness of LASSO Based Feature Selection},
  author={Li, Fuwei and Lai, Lifeng and Cui, Shuguang},
  journal={arXiv preprint arXiv:2010.10045},
  year={2020}
}

@article{wang2020achieving,
  title={Achieving Adversarial Robustness via Sparsity},
  author={Wang, Shufan and Liao, Ningyi and Xiang, Liyao and Ye, Nanyang and Zhang, Quanshi},
  journal={arXiv preprint arXiv:2009.05423},
  year={2020}
}


% Datasets
@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@misc{fisher1936uci,
  title={UCI machine learning repository: Iris data set},
  author={Fisher, Ronald A},
  year={1936}
}

% Review
@article{hao2020adversarial,
  title={Adversarial attacks and defenses in images, graphs and text: A review},
  author={Hao-Chen, Han Xu Yao Ma and Deb, Liu Debayan and Anil, Hui Liu Ji-Liang Tang and Jain, K},
  journal={International Journal of Automation and Computing},
  volume={17},
  number={2},
  pages={151--178},
  year={2020},
  publisher={Springer}
}

@article{lecun1995mnist,
  title={Learning algorithms for classification: A comparison on handwritten digit recognition},
  author={LeCun, Yann and Jackel, LD and Bottou, L{\'e}on and Cortes, Corinna and Denker, John S and Drucker, Harris and Guyon, Isabelle and Muller, UA and Sackinger, Eduard and Simard, Patrice and others},
  journal={Neural Networks},
  volume={261},
  pages={276},
  year={1995},
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{shan2020gotta,
  title={Gotta Catch'Em All: Using Honeypots to Catch Adversarial Attacks on Neural Networks},
  author={Shan, Shawn and Wenger, Emily and Wang, Bolun and Li, Bo and Zheng, Haitao and Zhao, Ben Y},
  booktitle={Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  pages={67--83},
  year={2020}
}

@article{xu2017feature,
  title={Feature squeezing: Detecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  journal={arXiv preprint arXiv:1704.01155},
  year={2017}
}

@article{xu2017feature,
  title={Feature squeezing: Detecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  journal={arXiv preprint arXiv:1704.01155},
  year={2017}
}

@inproceedings{cwattack,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle=oakland,
  year={2017},
}